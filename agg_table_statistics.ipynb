{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull aggregated table and run first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pymongo\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import functions as fn\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve information to connect to the database\n",
    "keys = fn.get_keys(\"/Users/jjherranzsarrion/.secret/local_info.json\")\n",
    "username = keys['username']\n",
    "password = keys['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your time ranges and add them in variables\n",
    "train_window_end = '2018-07-28 23:59:59'\n",
    "test_window_start = '2018-07-29 00:00:00'\n",
    "test_window_end = '2018-07-29 23:59:59'\n",
    "previous_day_start = '2018-07-28 00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information to calculate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features 1 and 2: Number of days the account has been opened and personalised bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info(username, password, train_window_end):\n",
    "    \"\"\" Function that returns the time period since the user opened the account and whether\n",
    "        or not they have a personalised bio.\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT user_id, about_personalised as personalised_bio,\n",
    "            SUM(CAST('{train_window_end}' AS timestamp) - date_joined) as time_since_account_inception\n",
    "            FROM users\n",
    "            GROUP BY (user_id, about_personalised);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    user_info_df = pd.DataFrame(cursor.fetchall())\n",
    "    user_info_df.columns = [x[0] for x in cursor.description]\n",
    "    return user_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_df = fn.user_info(username, password, train_window_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features 3, 4, and 5: Mean and Max time between previous transaction made and number of transactions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payed_transactions(username, password, train_window_end):\n",
    "    \"\"\" Function that returns the total number of transactions made during a given period and\n",
    "        the mean, max of the previous transactions made.\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT DISTINCT u.user_id, MAX(p1.diff_time) as max_time_diff_made_trans,\n",
    "                   AVG(p1.diff_time) as mean_time_diff_made_trans,\n",
    "                   COUNT (DISTINCT p1.payment_id) as n_transactions_made\n",
    "            FROM (SELECT p.actor_id, p.payment_id,\n",
    "                         (LEAD(p.date_created, 1) OVER (PARTITION BY p.actor_id ORDER BY p.date_created)\n",
    "                         - p.date_created) as diff_time\n",
    "                  FROM payments p\n",
    "                  WHERE p.date_created <= CAST('{train_window_end}' AS timestamp)) as p1\n",
    "            INNER JOIN users u ON u.user_id = p1.actor_id\n",
    "            GROUP BY (u.user_id);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    payed_transactions_df = pd.DataFrame(cursor.fetchall())\n",
    "    payed_transactions_df.columns = [x[0] for x in cursor.description]\n",
    "    return payed_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "payed_transactions_df = fn.payed_transactions(username, password, train_window_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features 6, 7, and 8: Mean and Max time between previous transaction received and n transactions received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def received_transactions(username, password, train_window_end):\n",
    "    \"\"\" Function that returns the total number of transactions received during a given period and\n",
    "        the mean, max of the previous transactions received.\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT DISTINCT u.user_id, MAX(p1.diff_time) as max_time_diff_received_trans,\n",
    "                   AVG(p1.diff_time) as mean_time_diff_received_trans,\n",
    "                   COUNT (DISTINCT p1.payment_id) as n_transactions_received\n",
    "            FROM (SELECT p.target_user_id, p.payment_id,\n",
    "                         (LEAD(p.date_created, 1) OVER (PARTITION BY p.target_user_id ORDER BY p.date_created)\n",
    "                         - p.date_created) as diff_time\n",
    "                  FROM payments p\n",
    "                  WHERE p.date_created <= CAST('{train_window_end}' AS timestamp)) as p1\n",
    "            INNER JOIN users u ON u.user_id = p1.target_user_id\n",
    "            GROUP BY (u.user_id);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    received_transactions_df = pd.DataFrame(cursor.fetchall())\n",
    "    received_transactions_df.columns = [x[0] for x in cursor.description]\n",
    "    return received_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "received_transactions_df = fn.received_transactions(username, password, train_window_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 9: Total number of transactions made the previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transactions_made_previous_day(username, password, previous_day_start, train_window_end):\n",
    "    \"\"\" Function that returns the total number of transactions made the previos day to our \n",
    "        testing time frame.\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT u.user_id, COUNT (DISTINCT p.payment_id) as n_trans_made_yest\n",
    "            FROM payments p\n",
    "            INNER JOIN users u ON u.user_id = p.actor_id\n",
    "            WHERE p.date_created >= CAST('{previous_day_start}' AS timestamp)\n",
    "            AND p.date_created <= CAST('{train_window_end}' AS timestamp)\n",
    "            GROUP BY (u.user_id);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    trans_made_yest_df = pd.DataFrame(cursor.fetchall())\n",
    "    trans_made_yest_df.columns = [x[0] for x in cursor.description]\n",
    "    return trans_made_yest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions_made_previous_day_df = fn.transactions_made_previous_day(username, password,\n",
    "                                                                      previous_day_start, \n",
    "                                                                      train_window_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange, no user made more than one transaction in the period of 2018-08-01 00:00:00 until 2018-08-07 and there were only 50 transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 10: Total number of transactions received in the previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactions_rec_previous_day(username, password, previous_day_start, train_window_end):\n",
    "    \"\"\" Function that returns the total number of transactions received the previos day \n",
    "        to our testing time frame.\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT u.user_id, COUNT (DISTINCT p.payment_id) as n_trans_rec_yest\n",
    "            FROM payments p\n",
    "            INNER JOIN users u ON u.user_id = p.target_user_id\n",
    "            WHERE p.date_created >= CAST('{previous_day_start}' AS timestamp)\n",
    "            AND p.date_created <= CAST('{train_window_end}' AS timestamp)\n",
    "            GROUP BY (u.user_id);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    trans_rec_yest_df = pd.DataFrame(cursor.fetchall())\n",
    "    trans_rec_yest_df.columns = [x[0] for x in cursor.description]\n",
    "    return trans_rec_yest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_rec_previous_day_df = fn.transactions_rec_previous_day(username, password,\n",
    "                                                                    previous_day_start, \n",
    "                                                                    train_window_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the aggregated statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes for users that payed transactions\n",
    "\n",
    "def made(username, password, previous_day_start, train_window_end):\n",
    "    \"Function that returns a dataframe with combined statistics for payers\"\n",
    "    payed_transactions_df = payed_transactions(username, password, train_window_end)\n",
    "    transactions_made_previous_day_df = transactions_made_previous_day(username, password,\n",
    "                                                                   previous_day_start, \n",
    "                                                                   train_window_end)\n",
    "    # Outer join because not everyone who has previously made a transaction necessarily made one yesterday\n",
    "    trans_made = pd.merge(payed_transactions_df, transactions_made_previous_day_df, \n",
    "                          'outer', on='user_id') \n",
    "    # Filling with 0s the null values that arise when users have made a transaction but not yesterday\n",
    "    trans_made.fillna(0, inplace=True)\n",
    "    return trans_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes for users that received transactions\n",
    "\n",
    "def received(username, password, previous_day_start, train_window_end):\n",
    "    \"Function that returns a dataframe with combined statistics for payees\"\n",
    "    received_transactions_df = received_transactions(username, password, train_window_end)\n",
    "    transactions_rec_previous_day_df = transactions_rec_previous_day(username, password,\n",
    "                                                                 previous_day_start, \n",
    "                                                                 train_window_end)\n",
    "    # Outer join because not everyone who has previously received a transaction necessarily received one yesterday\n",
    "    trans_rec = pd.merge(received_transactions_df, transactions_rec_previous_day_df, \n",
    "                          'outer', on='user_id') \n",
    "    # Filling with 0s the null values that arise when users have received a transaction but not yesterday\n",
    "    trans_rec.fillna(0, inplace=True)\n",
    "    return trans_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes for users that received transactions\n",
    "\n",
    "def transactions(username, password, previous_day_start, train_window_end):\n",
    "    \"Function that returns a dataframe with combined statistics for payees\"\n",
    "    made_df = made(username, password, previous_day_start, train_window_end)\n",
    "    received_df = received(username, password, previous_day_start, train_window_end)\n",
    "    # Outer join because not everyone who has made a transaction necessarily received one and viceversa\n",
    "    trans = pd.merge(made_df, received_df, 'outer', on='user_id') \n",
    "    # Filling with 0s the null values that arise when users have made a transaction but not received one\n",
    "    trans.fillna(0, inplace=True)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the user statistics with the user information\n",
    "\n",
    "def agg_table(username, password, previous_day_start, train_window_end):\n",
    "    \"Function that returns a dataframe with user information and relevant statistics\"\n",
    "    user_df = user_info(username, password, train_window_end)\n",
    "    trans_df = transactions(username, password, previous_day_start, train_window_end)\n",
    "    # Inner join because all users should have either made or received a transaction,\n",
    "    # so they will have a user_id\n",
    "    agg_table = pd.merge(user_df, trans_df, 'inner', on='user_id')\n",
    "    \n",
    "    time_delta_cols = (['time_since_account_inception', 'max_time_diff_made_trans',\n",
    "                        'max_time_diff_received_trans', 'mean_time_diff_made_trans', \n",
    "                        'mean_time_diff_received_trans'])\n",
    "    \n",
    "    for col in time_delta_cols:\n",
    "        agg_table[f'{col}'] = [diff.total_seconds() for diff in agg_table[f'{col}']]\n",
    "    return agg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_statistics = fn.get_aggregated_user_statistics(username, password, previous_day_start, train_window_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_statistics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_statistics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting my y value\n",
    "\n",
    "def extract_target(username, password, test_window_start, test_window_end):\n",
    "    \"\"\"Function that returns the target variable (whether someone made a transaction \n",
    "       during a given time period) or not\"\"\"\n",
    "    cursor = extracting_cursor(username, password)\n",
    "    q = f\"\"\"SELECT u.user_id, COUNT (DISTINCT p.payment_id) as n_transactions_made_29th\n",
    "            FROM payments p\n",
    "            INNER JOIN users u ON u.user_id = p.actor_id\n",
    "            WHERE p.date_created >= CAST('{test_window_start}' AS timestamp)\n",
    "            AND p.date_created <= CAST('{test_window_end}' AS timestamp)\n",
    "            GROUP BY (u.user_id);\"\"\"\n",
    "    cursor.execute(q)\n",
    "    tran_or_not_df = pd.DataFrame(cursor.fetchall())\n",
    "    tran_or_not_df.columns = [x[0] for x in cursor.description]\n",
    "    tran_or_not_df['n_transactions_made_29th'] = [1 for trans in tran_or_not_df['n_transactions_made_29th']]\n",
    "    return tran_or_not_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_or_not_df = extract_target(username, password, test_window_start, test_window_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with agg table to include nulls\n",
    "\n",
    "complete_table = pd.merge(agg_table, tran_or_not_df, 'outer', on='user_id')\n",
    "complete_table.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_table.drop('n_transactions_made_29th', axis=1)\n",
    "y = complete_table['n_transactions_made_29th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12, solver='liblinear')\n",
    "model_log = logreg.fit(X_train_sc, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = logreg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print('Testing Precision: ', precision_score(y_test, y_hat_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Testing Recall: ', recall_score(y_test, y_hat_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Testing F1-Score: ',f1_score(y_test, y_hat_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
