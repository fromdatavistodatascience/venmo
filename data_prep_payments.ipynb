{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a unique payments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import functions as fn\n",
    "import io\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting payment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the above mentioned pickle\n",
    "with open('initial_5pct_transactions.pkl', 'rb') as f:\n",
    "    initial_5pct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = []\n",
    "keys = (['note', 'action', 'status', 'date_created', 'id',\n",
    "         'merchant_split_purchase', 'audience', 'date_completed'])\n",
    "subdictionary_keys = ['target', 'actor']\n",
    "# Onle including the keys in the payment target subdictionary that contains values\n",
    "target_keys = ['redeemable_target', 'type']\n",
    "user_key = ['user']\n",
    "actor_key = ['id']\n",
    "\n",
    "for transaction in initial_5pct:\n",
    "    payment = {}\n",
    "    payment_details = transaction['payment']\n",
    "    for key, val in payment_details.items():\n",
    "        if key in keys:\n",
    "            unpacked = f'{key}'\n",
    "            payment[unpacked] = val\n",
    "        elif key in subdictionary_keys:\n",
    "            for subkey, subval in val.items():\n",
    "                if subkey in target_keys:\n",
    "                    subkey_unpacked = f'{key}_{subkey}'\n",
    "                    payment[subkey_unpacked] = subval\n",
    "                elif subkey in user_key:\n",
    "                    subkey_unpacked = f'{key}_{subkey}_{actor_key[0]}'\n",
    "                    # Some transactions don't have end users and as such they are deemed\n",
    "                    # as pending or cancelled. However, these should not be dropped because \n",
    "                    # the user still made a transaction.\n",
    "                    try:\n",
    "                        subkey_unpacked_val = transaction['payment'][f'{key}'][f'{subkey}'][f'{actor_key[0]}']\n",
    "                        payment[subkey_unpacked] = subkey_unpacked_val\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                elif subkey in actor_key:\n",
    "                    subkey_unpacked = f'{key}_{subkey}'\n",
    "                    payment[subkey_unpacked] = subval\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "    payments.append(payment.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = pd.DataFrame(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df['date_completed'] = pd.to_datetime(payments_df['date_completed'], format='%Y-%m-%dT%H:%M:%S')\n",
    "payments_df['date_created'] = pd.to_datetime(payments_df['date_created'], format='%Y-%m-%dT%H:%M:%S')\n",
    "payments_df = payments_df.sort_values(['actor_id', 'date_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify payers who have pending or cancelled transactions\n",
    "unsettled_payer_ids = payments_df.loc[payments_df['status'] != 'settled']['actor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the payers that have at least one unsettled transaction\n",
    "unique_unsettled_payer_ids = unsettled_payer_ids.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 2349 payers who have made at least one unsettled transaction'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'There are {len(unique_unsettled_payer_ids)} payers who have made at least one unsettled transaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify payers that made a settled transaction given that they had at least one unsettled transaction\n",
    "actors_with_settled_and_unsettled_trans = set()\n",
    "actors_with_unsettled_transactions = set()\n",
    "for actor in unique_unsettled_payer_ids:\n",
    "    actor_specific_df = payments_df.loc[payments_df['actor_id'] == f'{actor}']\n",
    "    for status in actor_specific_df['status']:\n",
    "        if status != 'settled':\n",
    "            actors_with_unsettled_transactions.add(actor)\n",
    "        else:\n",
    "            actors_with_settled_and_unsettled_trans.add(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the payers that have only made unsettled transactions\n",
    "actors_with_only_unsettled_transactions = (actors_with_unsettled_transactions - \n",
    "                                           actors_with_settled_and_unsettled_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df['unsettled'] = ([1 if actor in actors_with_only_unsettled_transactions else 0 \n",
    "                             for actor in payments_df['actor_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the transactions which users with unsettled payments have made within 10 minutes of each other.\n",
    "\n",
    "# This 10 minute rule though is not very specific. User 2534007896014848135 waited for more than an hour\n",
    "# but appears to only want to make one transaction. This is a loopwhole through our functions\n",
    "duplicated_transaction_ids = set()\n",
    "\n",
    "for actor in actors_with_settled_and_unsettled_trans:\n",
    "    #Creating actor specific dataframes\n",
    "    settled_and_unsettled_trans_df = payments_df.loc[payments_df['actor_id'] == f'{actor}']\n",
    "    transaction_dates = [date for date in settled_and_unsettled_trans_df['date_created']]\n",
    "    #Separating the dates of created payments for each user\n",
    "    for i in range(len(transaction_dates)-1):\n",
    "        time_diff = transaction_dates[i+1] - transaction_dates[i]\n",
    "        time_diff = time_diff.total_seconds()\n",
    "        #If the payments are made within 10 minutes then identify those transactions\n",
    "        if time_diff < 600: #WHY 10 MINUTES THOUGH?\n",
    "            date_tuple = (transaction_dates[i], transaction_dates[i+1])\n",
    "            #Create a new dataframe for each user that contains transactions made within 10 minute of each other\n",
    "            transaction_within_10 = (\n",
    "                settled_and_unsettled_trans_df.loc[settled_and_unsettled_trans_df['date_created'].isin(date_tuple)])\n",
    "            #Extract the status' of both transactions\n",
    "            for status in transaction_within_10['status']:\n",
    "            #If one of the status' is settled it means that the rest are duplicates\n",
    "                if status != 'settled':\n",
    "                    duplicated_id = transaction_within_10.loc[transaction_within_10['status'] == status]['id']\n",
    "                    duplicated_transaction_ids.add(duplicated_id.any())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = payments_df.sort_values(['actor_id', 'date_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out duplicated and non duplicated transactions from the unsettled bunch\n",
    "duplicated_unsettled_transaction_ids = set()\n",
    "non_duplicated_unsettled_transaction_ids = set()\n",
    "\n",
    "for actor in actors_with_only_unsettled_transactions:\n",
    "    #Creating actor specific dataframes\n",
    "    unsettled_trans_df = payments_df.loc[payments_df['actor_id'] == f'{actor}']\n",
    "    transaction_dates = [date for date in unsettled_trans_df['date_created']]\n",
    "    #Separating the dates of created payments for each user\n",
    "    for i in range(len(transaction_dates)-1):\n",
    "        time_diff = transaction_dates[i+1] - transaction_dates[i]\n",
    "        time_diff = time_diff.total_seconds()\n",
    "        #If the payments are made within 10 minutes then identify those transactions\n",
    "        if time_diff < 600: #WHY 10 MINUTES THOUGH?\n",
    "            first_trans_id = (\n",
    "                unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i]]['id'])\n",
    "            non_duplicated_unsettled_transaction_ids.add(first_trans_id.any())\n",
    "            duplicated_trans_id = (\n",
    "                unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i+1]]['id'])\n",
    "            duplicated_unsettled_transaction_ids.add(duplicated_trans_id.any())\n",
    "        else:\n",
    "            non_duplicated_transaction_id = (\n",
    "                    unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i]]['id'])\n",
    "            non_duplicated_unsettled_transaction_ids.add(non_duplicated_transaction_id.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df['duplicated_transactions'] = ([1 if _id in duplicated_unsettled_transaction_ids else 0 \n",
    "                                           for _id in payments_df['id']])\n",
    "payments_df['non_duplicated_transactions'] = ([1 if _id in non_duplicated_unsettled_transaction_ids else 0 \n",
    "                                               for _id in payments_df['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df['true_transactions'] = ([1 if status=='settled' else 0 \n",
    "                                     for status in payments_df['status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df['false_transactions'] = ([1 if _id in duplicated_transaction_ids else 0 \n",
    "                                     for _id in payments_df['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>date_created</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>actor_id</th>\n",
       "      <th>merchant_split_purchase</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>target_type</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>target_redeemable_target</th>\n",
       "      <th>action</th>\n",
       "      <th>audience</th>\n",
       "      <th>unsettled</th>\n",
       "      <th>true_transactions</th>\n",
       "      <th>false_transactions</th>\n",
       "      <th>duplicated_transactions</th>\n",
       "      <th>non_duplicated_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>52945</td>\n",
       "      <td>ok</td>\n",
       "      <td>2018-07-27 08:20:40</td>\n",
       "      <td>2532618399310152539</td>\n",
       "      <td>pending</td>\n",
       "      <td>2532561196679168944</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>pay</td>\n",
       "      <td>public</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53109</td>\n",
       "      <td>ok</td>\n",
       "      <td>2018-07-27 08:21:38</td>\n",
       "      <td>2532618887619412607</td>\n",
       "      <td>pending</td>\n",
       "      <td>2532561196679168944</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>pay</td>\n",
       "      <td>public</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      note        date_created                   id   status  \\\n",
       "52945   ok 2018-07-27 08:20:40  2532618399310152539  pending   \n",
       "53109   ok 2018-07-27 08:21:38  2532618887619412607  pending   \n",
       "\n",
       "                  actor_id merchant_split_purchase date_completed target_type  \\\n",
       "52945  2532561196679168944                    None            NaT       phone   \n",
       "53109  2532561196679168944                    None            NaT       phone   \n",
       "\n",
       "      target_user_id target_redeemable_target action audience  unsettled  \\\n",
       "52945            NaN                     None    pay   public          1   \n",
       "53109            NaN                     None    pay   public          1   \n",
       "\n",
       "       true_transactions  false_transactions  duplicated_transactions  \\\n",
       "52945                  0                   0                        0   \n",
       "53109                  0                   0                        1   \n",
       "\n",
       "       non_duplicated_transactions  \n",
       "52945                            1  \n",
       "53109                            0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payments_df.loc[payments_df['actor_id'] == '2532561196679168944']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If users have only made one unsettled transaction, flag users. \n",
    "\n",
    "- If those users opened the account recently, it is less likely that they will make a transaction soon given their bad experience with the app. Moreover, we are looking at a history of 2 months, so if they recently opened an account, made an unsuccessful transaction and haven't made one again then we are better off dropping them as they will just be adding noise. \n",
    "\n",
    "- On the other hand, if their account has been active for a longer time period this means that they have probable made more than the unsuccesful transaction in the past. So it is best to keep them.\n",
    "\n",
    "- If they have made more than one transaction in a close time period, then drop unsucessful and keep succesful one only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2422 values missing in the date_completed and target_user_id col come from those transactions that don't have a payee and as such they are never completed (deemed as pending or cancelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename col id to payment_id for easier recognition in the db\n",
    "payments_df = payments_df.rename(columns = {\"id\": \"payment_id\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the non null values in merchant_split_purchase\n",
    "payments_df.loc[payments_df['merchant_split_purchase'].notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all appear to be charges instead of payments. We will unpack the merchant_split_purchase into two different cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = payments_df.drop('merchant_split_purchase', 1).assign(**payments_df['merchant_split_purchase']\n",
    "                                                                    .dropna().apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to miror the json structure\n",
    "payments_df = payments_df.rename(columns = {\"authorization_id\": \"merchant_authorization_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the non null values in target_redeemable_target\n",
    "payments_df.loc[payments_df['target_redeemable_target'].notnull()]['target_redeemable_target'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thought process as with the merchant_split_purchase col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = payments_df.drop('target_redeemable_target', 1).assign(**payments_df['target_redeemable_target']\n",
    "                                                                     .dropna().apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to miror the json structure\n",
    "payments_df = payments_df.rename(columns = {\"display_name\": \"target_redeemable_target_display_name\",\n",
    "                                            \"type\": \"target_redeemable_target_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping resulting payments table into the venmo_transactions db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve information about the venmo_transactions db\n",
    "keys = fn.get_keys(\"/Users/jjherranzsarrion/.secret/local_info.json\")\n",
    "username = keys['username']\n",
    "password = keys['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move payments_df table into the database\n",
    "engine = create_engine(f'postgresql://{username}:{password}@localhost/venmo_transactions')\n",
    "payments_df.to_sql('payments', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA:\n",
    "                \n",
    "            \n",
    "            \n",
    "            if first_trans < transaction_dates[i]:\n",
    "                first_trans_id = (\n",
    "                    unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i]]['id'])\n",
    "                first_intended_unsettled_transaction.add(first_trans_id.any())\n",
    "                first_trans = transaction_dates[i]\n",
    "            else:\n",
    "                duplicated_trans_id = (\n",
    "                    unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i+1]]['id'])\n",
    "                first_intended_unsettled_transaction.add(first_trans_id.any())\n",
    "        else:\n",
    "            non_duplicated_transaction_id = (\n",
    "                    unsettled_trans_df.loc[unsettled_trans_df['date_created'] == transaction_dates[i]]['id'])\n",
    "            non_duplicated_unsettled_transaction_ids.add(non_duplicated_transaction_id.any())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
