{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a unique payments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pymongo\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import functions as fn\n",
    "import psycopg2\n",
    "import io\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting payment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the above mentioned pickle\n",
    "with open('initial_5pct_transactions.pkl', 'rb') as f:\n",
    "    initial_5pct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = []\n",
    "keys = (['note', 'action', 'status', 'date_created', 'id',\n",
    "         'merchant_split_purchase', 'audience', 'date_completed'])\n",
    "subdictionary_keys = ['target', 'actor']\n",
    "# Onle including the keys in the payment target subdictionary that contains values\n",
    "target_keys = ['redeemable_target', 'type']\n",
    "user_key = ['user']\n",
    "actor_key = ['id']\n",
    "\n",
    "for transaction in initial_5pct:\n",
    "    payment = {}\n",
    "    payment_details = transaction['payment']\n",
    "    for key, val in payment_details.items():\n",
    "        if key in keys:\n",
    "            unpacked = f'{key}'\n",
    "            payment[unpacked] = val\n",
    "        elif key in subdictionary_keys:\n",
    "            for subkey, subval in val.items():\n",
    "                if subkey in target_keys:\n",
    "                    subkey_unpacked = f'{key}_{subkey}'\n",
    "                    payment[subkey_unpacked] = subval\n",
    "                elif subkey in user_key:\n",
    "                    subkey_unpacked = f'{key}_{subkey}_{actor_key[0]}'\n",
    "                    try:\n",
    "                        subkey_unpacked_val = transaction['payment'][f'{key}'][f'{subkey}'][f'{actor_key[0]}']\n",
    "                        payment[subkey_unpacked] = subkey_unpacked_val\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "                elif subkey in actor_key:\n",
    "                    subkey_unpacked = f'{key}_{subkey}'\n",
    "                    payment[subkey_unpacked] = subval\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "    payments.append(payment.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = pd.DataFrame(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2422 values missing in the date_completed and target_user_id col come from those transactions that don't have a payee and as such they are never completed (deemed as pending or cancelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename col id to payment_id for easier recognition in the db\n",
    "payments_df = payments_df.rename(columns = {\"id\": \"payment_id\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date_created and date_completed objects into a datetime.datetime field\n",
    "payments_df['date_completed'] = pd.to_datetime(payments_df['date_completed'], format='%Y-%m-%dT%H:%M:%S')\n",
    "payments_df['date_created'] = pd.to_datetime(payments_df['date_created'], format='%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the non null values in merchant_split_purchase\n",
    "payments_df.loc[payments_df['merchant_split_purchase'].notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all appear to be charges instead of payments. We will unpack the merchant_split_purchase into two different cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = payments_df.drop('merchant_split_purchase', 1).assign(**payments_df['merchant_split_purchase']\n",
    "                                                                    .dropna().apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to miror the json structure\n",
    "payments_df = payments_df.rename(columns = {\"authorization_id\": \"merchant_authorization_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the non null values in target_redeemable_target\n",
    "payments_df.loc[payments_df['target_redeemable_target'].notnull()]['target_redeemable_target'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thought process as with the merchant_split_purchase col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df = payments_df.drop('target_redeemable_target', 1).assign(**payments_df['target_redeemable_target']\n",
    "                                                                     .dropna().apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to miror the json structure\n",
    "payments_df = payments_df.rename(columns = {\"display_name\": \"target_redeemable_target_display_name\",\n",
    "                                            \"type\": \"target_redeemable_target_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping resulting payments table into the venmo_transactions db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move unique payments table into database\n",
    "engine = create_engine('postgresql://jjherranzsarrion:jj2gNozalo@localhost/venmo_transactions')\n",
    "payments_df.to_sql('payments', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
