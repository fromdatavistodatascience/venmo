{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing EDA on Venmo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pymongo\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has to be exported from a Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the venmo transaction collection from the MongoDB\n",
    "venmo = fn.collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all transactions in the venmo data\n",
    "venmo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first transaction\n",
    "venmo.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in initial_5pct function to generate a pickle with the first ~350k transactions\n",
    "#initial_5pct = fn.initial_5pct(venmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the above mentioned pickle\n",
    "with open('initial_5pct_transactions.pkl', 'rb') as f:\n",
    "    initial_5pct = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = venmo.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = []\n",
    "transaction = {}\n",
    "keys = ['mentions', 'likes', 'comments','app']\n",
    "payment_keys = (['amount', 'note', 'action', 'status', 'date_created', 'date_reminded',\n",
    "                 'id', 'date_authorized', 'merchant_split_purchase', 'audience', 'date_completed'])\n",
    "payment_inner_keys = ['target', 'actor']\n",
    "target_keys = ['redeemable_target', 'merchant', 'phone', 'email', 'type']\n",
    "actor_keys = [\"username\", \"friends_count\", \"is_active\", \"display_name\", \"friend_status\", \"email\",\n",
    "              \"first_name\", \"identity\", \"last_name\", \"is_blocked\", \"about\", \"profile_picture_url\", \"id\",\n",
    "              \"phone\", \"trust_request\", \"date_joined\", \"is_group\"]    \n",
    "\n",
    "for key, val in first.items():\n",
    "    if key in keys:\n",
    "        for subkeys, subvals in val.items():\n",
    "            unpacked = f'{key}_{subkeys}'\n",
    "            transaction[unpacked] = subvals\n",
    "    elif key == 'payment':\n",
    "        for payment_subkeys, payment_subvals in val.items():\n",
    "            if payment_subkeys in payment_keys:\n",
    "                payments_unpacked = f'{key}_{payment_subkeys}'\n",
    "                transaction[payments_unpacked] = payment_subvals\n",
    "            elif payment_subkeys in payment_inner_keys:\n",
    "                for payment_target_actor_subkeys, payment_target_actor_subvalues in payment_subvals.items():\n",
    "                    if payment_target_actor_subkeys in target_keys:\n",
    "                        payment_target_subkeys_unpacked = f'{key}_{payment_subkeys}_{payment_target_actor_subkeys}'\n",
    "                        transaction[payment_target_subkeys_unpacked] = payment_target_actor_subvalues\n",
    "                    elif payment_target_actor_subkeys in actor_keys:\n",
    "                        payment_actor_subkeys_unpacked = f'{key}_{payment_subkeys}_{payment_target_actor_subkeys}'\n",
    "                        transaction[payment_actor_subkeys_unpacked] = payment_target_actor_subvalues\n",
    "                    elif payment_target_actor_subkeys == 'user':\n",
    "                        for payment_target_user_subkeys, payment_target_user_subvalues in payment_target_actor_subvalues.items():\n",
    "                            payment_actor_user_subkeys_unpacked = (\n",
    "                                f'{key}_{payment_subkeys}_{payment_target_actor_subkeys}_{payment_target_user_subkeys}'\n",
    "                            )\n",
    "                            transaction[payment_actor_user_subkeys_unpacked] = payment_target_user_subvalues\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "        continue\n",
    "    else:\n",
    "        transaction[key] = val\n",
    "transaction_df.append(transaction.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting payer information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(initial_5pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the unique ids for each payer in the intial_5pct of transactions\n",
    "payer_ids = set()\n",
    "for transaction in initial_5pct:\n",
    "    actor = transaction['payment']['actor']\n",
    "    actor_id = actor['id']\n",
    "    payer_ids.add(actor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f'The number of unique payers in the first 5% of transactions is {len(payer_ids)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform user information into a dataframe\n",
    "payers = []\n",
    "payer_ids = set()\n",
    "counter = 0\n",
    "for transaction in initial_5pct:\n",
    "    actor = transaction['payment']['actor']\n",
    "    actor_id = actor['id']\n",
    "    if actor_id in payer_ids:\n",
    "        continue\n",
    "    else:\n",
    "        payer_ids.add(actor_id)\n",
    "        payer = {}\n",
    "        for key, val in transaction['payment']['actor'].items():\n",
    "            payer[key] = val\n",
    "        payers.append(payer.copy())\n",
    "\n",
    "payers_df = pd.DataFrame(payers)\n",
    "payers_df['payer'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the dataframe\n",
    "payers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate nulls to see them more clearly\n",
    "payers_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the null value for about, looks like it could be the same row as for date_joined and username.\n",
    "payers_df.loc[payers_df['about'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that it is we are going to drop said value.\n",
    "payers_df.drop(axis=0, index=294315, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that only have null values\n",
    "null_cols = ['email', 'friend_status', 'friends_count', 'identity', 'phone', 'trust_request']\n",
    "payers_df.drop(labels = null_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payers_df['about'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date joined object into a datetime.datetime field\n",
    "\n",
    "payers_df['date_joined'] = pd.to_datetime(df['date'])\n",
    "new_dates = [datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S') for x in payers_df['date_joined']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
